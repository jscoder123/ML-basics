{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "OpenCV_Basics.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suprajaarthi/ML-basics/blob/main/OpenCV_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcex0ZbF3lA5"
      },
      "source": [
        "# OpenCV Tutorial\n",
        "\n",
        "OpenCV was started at Intel in 1999 by Gary Bradsky, and the first release came out in 2000. \n",
        "\n",
        "- It is a Python library which is designed to solve computer vision problems. OpenCV was originally developed in 1999 by Intel but later it was supported by Willow Garage.\n",
        "\n",
        "- It supports a wide variety of programming languages such as C++, Python, Java etc. Support for multiple platforms including Windows, Linux, and MacOS.\n",
        "\n",
        "- OpenCV Python is nothing but a wrapper class for the original C++ library to be used with Python. Using this, all of the OpenCV array structures gets converted to/from NumPy arrays. This makes it easier to integrate it with other libraries which use NumPy. For example, libraries such as SciPy and Matplotlib."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnlnJXB53lA8"
      },
      "source": [
        "\n",
        "### **Chapter 1:** How to read, write, and display Images & Videos\n",
        "We will set up a basic understanding of how we can begin learning image processing with OpenCV by reading, writing, and displaying images as well videos using OpenCV methods like imshow(), imread(), etc. \n",
        "\n",
        "### **Chapter 2:** Basic Functions\n",
        "After we have established a basic understanding, we will learn about various methods on images to resize, blur, etc.\n",
        "\n",
        "### **Chapter 3:** Shapes and Texts\n",
        "We will learn about the various shapes that we can put the images into and with corresponding text values as their labels\n",
        "\n",
        "### **Chapter 4:** Joining Images\n",
        "This section particularly focuses on how we can join the images together.\n",
        "### **Chapter 5:** Mini-Projects - \n",
        "### - Face Detection on Images, Videos, & in Real-time\n",
        "### - Face and Eyes Detection in Real-time\n",
        "### - Pedestrians Detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjKKBYbl3lA9"
      },
      "source": [
        "## **OpenCV Github Link** https://github.com/opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R8j-kdo3lA-",
        "outputId": "ddb7de0d-4fe1-4320-99f8-dcbcfcc8cc35"
      },
      "source": [
        "import cv2 #Import the OpenCV Library\n",
        "import numpy as np\n",
        "\n",
        "print(cv2.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJP7dtRb3lBD"
      },
      "source": [
        "## CHAPTER 1\n",
        "\n",
        "### How to read, write, and display Images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R0y_I1P3lBE"
      },
      "source": [
        "#Reading & Displaying an Image\n",
        "\n",
        "img = cv2.imread('dog.jpg')\n",
        "#imread enables us to read an Image\n",
        "#The 2nd argumnet is a flag which specifies the way image should be read\n",
        "\n",
        "cv2.imshow(\"Output\", img) #Displaying the Image\n",
        "\n",
        "cv2.waitKey(0) #Delay. No. of Milliseconds for which we want to show our image window\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xln_W2M3lBF",
        "outputId": "44e179fc-3be9-4ae5-88a6-935d2e86d8bf"
      },
      "source": [
        "cv2.imwrite('copy_dog.jpg', img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHjYEDn63lBG"
      },
      "source": [
        "### How to read, write, and display Videos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av1x-XDP3lBJ"
      },
      "source": [
        "#Reading & Displaying a Video\n",
        "\n",
        "cap = cv2.VideoCapture(0) #If you want to display the Video File, just give the name of it inplace of 0\n",
        "\n",
        "# is a 4-byte identifier which specifies the format of a video stream\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc('X','V','I','D') \n",
        "\n",
        "out = cv2.VideoWriter('Name of Output File.avi', fourcc, 20.0, (640,480)) #No. of frames/s, Frame Size\n",
        "\n",
        "#Videos are just a sequence of Images\n",
        "#So, we will add a while loop to capture the frame continuously\n",
        "\n",
        "while True:\n",
        "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
        "    \n",
        "    if success == True:\n",
        "        \n",
        "        out.write(frame)\n",
        "        \n",
        "        cv2.imshow(\"Video\", frame)\n",
        "    \n",
        "        if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
        "            break\n",
        "            \n",
        "    else:\n",
        "        break\n",
        "        \n",
        "        \n",
        "cap.release() #Release the resources after recording\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "benRdYf33lBK"
      },
      "source": [
        "#Reading & Displaying a Video\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "cap.set(3, 640)#Width\n",
        "cap.set(4, 480)#Height\n",
        "cap.set(10, 100)#brightness\n",
        "\n",
        "#Videos are just a sequence of Images\n",
        "#So, we will add a while loop to go through each frame\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read() #img variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
        "    cv2.imshow(\"Video\", img)\n",
        "      \n",
        "   \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
        "        break\n",
        "        \n",
        "cap.release() #Release the resources after recording\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pf8ck8z3lBO"
      },
      "source": [
        "## CHAPTER 2\n",
        "\n",
        "### Basic Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoIKh1mq3lBR"
      },
      "source": [
        "#Converting the Image into Gray Scale\n",
        "\n",
        "#Reading an Image\n",
        "\n",
        "img = cv2.imread('dog.jpg') \n",
        "\n",
        "imgGray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)#Converting the Image into Gray Scale\n",
        "\n",
        "cv2.imshow('GrayScale Image',imgGray)\n",
        "\n",
        "cv2.imwrite('copy_lena.png', imgGray)\n",
        "\n",
        "\n",
        "\n",
        "#imgGray1 = cv2.cvtColor(imgGray, cv2.COLOR_GRAY2RGB)#Converting the Image into Gray Scale\n",
        "\n",
        "#cv2.imshow('GrayScale Image1',imgGray1)\n",
        "\n",
        "\n",
        "cv2.waitKey(0) #Delay. No. of Milliseconds for which we want to show our image window\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bLfokqJ3lBS"
      },
      "source": [
        "#Blur Function to Blur the Image\n",
        "\n",
        "#Reading an Image\n",
        "\n",
        "img = cv2.imread('dog.jpg') \n",
        "\n",
        "imgBlur = cv2.GaussianBlur(img, (21,21), 0)\n",
        "#(7,7) is the Kernel Size (Amount of Blur) which is always odd. So, (3,3), (5,5), etc.\n",
        "# 0 is Sig function (Standard Deviation along X-Direction) \n",
        "\n",
        "cv2.imshow('Blurred Image',imgBlur)\n",
        "\n",
        "cv2.waitKey(0) #Delay. No. of Milliseconds for which we want to show our image window\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXZhkkmp3lBT"
      },
      "source": [
        "#Edge Detector - Canny \n",
        "\n",
        "img = cv2.imread('dog.jpg') #Reading an Image\n",
        "\n",
        "imgCanny = cv2.Canny(img, 150, 200)#Threshold Values\n",
        "\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "#Type of the object which is unsigned integer of 8 bits which means the values can range from 0 to 255\n",
        "\n",
        "imgDilation = cv2.dilate(imgCanny, kernel, iterations = 1)#dilate function is used when the Edges are not properly connected\n",
        "\n",
        "imgErosion = cv2.erode(imgDilation, kernel, iterations = 1)#Erosion function is used when we want to thin (Erode) the Image\n",
        "\n",
        "\n",
        "#iterations - How much thickness do we actually need?\n",
        "\n",
        "cv2.imshow('Canny Image',imgCanny)\n",
        "cv2.imshow('Dilation Image',imgDilation)\n",
        "cv2.imshow('Erosion Image',imgErosion)\n",
        "\n",
        "\n",
        "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. No. of Milliseconds for which we want to show our image window\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptwtHgkC3lBU",
        "outputId": "974ebffc-6cdb-458b-a84e-55b0f40cbc06"
      },
      "source": [
        "#Resizing the Image\n",
        "\n",
        "#Reading & Displaying an Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('dog.jpg') \n",
        "#Reading an Image\n",
        "\n",
        "cv2.imshow(\"Output\", img) #Displaying the Image\n",
        "\n",
        "print(img.shape) #Shape of the Image (Height, Width, No.of Channels(RGB))\n",
        "\n",
        "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. No. of Milliseconds for which we want to show our image window\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktcqg6TI3lBV"
      },
      "source": [
        "img_resize = cv2.resize(img, (200, 400)) # (Width, Height)\n",
        "\n",
        "cv2.imshow(\"Original Image\", img)\n",
        "cv2.imshow(\"Re-sized Image\", img_resize) #Displaying the Image\n",
        "\n",
        "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. If specified 1, it means 1 milliseconds\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTeRmjEX3lBV",
        "outputId": "973beaf6-4ba6-4e52-c071-14d1dcc30b64"
      },
      "source": [
        "#Cropping the Image\n",
        "\n",
        "img = cv2.imread('dog.jpg') #Reading an Image\n",
        "\n",
        "cv2.imshow(\"Output\", img) #Displaying the Image\n",
        "\n",
        "imgCropped = img[0:200, 200:500] #(Height, Width)\n",
        "\n",
        "cv2.imshow(\"Cropped Image\", imgCropped) #Displaying the Image\n",
        "\n",
        "print(img.shape) #Shape of the Image (Height, Width, No.of Channels(BGR))\n",
        "\n",
        "cv2.waitKey(0) #Delay. 0 Means Infinite Delay. If specified 1, it means 1 milliseconds\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxmfCd5C3lBW"
      },
      "source": [
        "## CHAPTER 3\n",
        "\n",
        "### Shapes and Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym4uWY7j3lBX",
        "outputId": "70bf4252-f726-4330-ef2d-75fd1e9ffd39"
      },
      "source": [
        "#0 means Black\n",
        "\n",
        "img = np.zeros((512, 512))#Print a Black Image. It is a GrayScale Image\n",
        "\n",
        "cv2.imshow(\"O\", img)\n",
        "\n",
        "print(img.shape)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90hzf2KX3lBX"
      },
      "source": [
        "#0 means Black\n",
        "\n",
        "img = np.zeros((512, 512, 3),np.uint8 )#Print a Black Image with 3 Channles RGB.\n",
        "\n",
        "#img[:] = 255, 0 , 0\n",
        "\n",
        "cv2.line(img, (0,0), (300,300), (0,255,255),3) #Staring Pt., Ending Pt., Color, Thickness\n",
        "\n",
        "cv2.imshow(\"O\", img)\n",
        "\n",
        "#print(img.shape)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvZPkVOn3lBY"
      },
      "source": [
        "cv2.rectangle(img, (0,0), (250,350), (0, 255, 255), cv2.FILLED) #cv2.FILLED is used to Fill the Rectangles\n",
        "\n",
        "cv2.imshow(\"O\", img)\n",
        "\n",
        "#print(img.shape)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuk5PM9G3lBY"
      },
      "source": [
        "cv2.circle(img, (400,50), 30 , (0, 255, 255), cv2.FILLED) #Center, Radius , Color\n",
        "\n",
        "cv2.imshow(\"O\", img)\n",
        "\n",
        "#print(img.shape)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfUIZCBc3lBY"
      },
      "source": [
        "cv2.putText(img, \"OpenCV\", (300, 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150,0), 1) #Staring Pt., Font, Scale, Color, Thickness\n",
        "\n",
        "cv2.imshow(\"O\", img)\n",
        "\n",
        "#print(img.shape)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_8kItQi3lBZ"
      },
      "source": [
        "## CHAPTER 4\n",
        "\n",
        "### Joining Images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_mQQGQo3lBZ"
      },
      "source": [
        "#How to Join Image Together\n",
        "\n",
        "img = cv2.imread('dog.jpg') #Reading an Image\n",
        "\n",
        "imgHor = np.hstack((img, img))#Images stacked in Horizonatl Direction\n",
        "\n",
        "cv2.imshow(\"Horizontal\", imgHor) #Displaying the Image\n",
        "\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2D8adIn3lBa"
      },
      "source": [
        "#How to Join Image Together\n",
        "\n",
        "img = cv2.imread('dog.jpg') #Reading an Image\n",
        "\n",
        "imgVer = np.vstack((img, img))#Images stacked in Horizonatl Direction\n",
        "\n",
        "cv2.imshow(\"Vertical\", imgVer) #Displaying the Image\n",
        "\n",
        "\n",
        "#Both the Images must have same Channels because they have a matrix and we cannot resize the Images\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqYRZqTc3lBa"
      },
      "source": [
        "## CHAPTER 5\n",
        "\n",
        "### Face Detection on an Image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g36ZbdS83lBa"
      },
      "source": [
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "img = cv2.imread('face.jpg') #Reading an Image\n",
        "\n",
        "img = cv2.resize(img, (1240,640))\n",
        "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
        "\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(img, (x,y),(x+w,y+h),(0,0,255),2)\n",
        "\n",
        "cv2.imshow(\"Output\", img) #Displaying the Image\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPGtiCeX3lBb"
      },
      "source": [
        "### Face Detection in Videos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnNuq2y93lBd"
      },
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture('vid.mp4')\n",
        "\n",
        "#Videos are just a sequence of Images\n",
        "#So, we will add a while loop to capture the frame continuously\n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "\n",
        "while True:\n",
        "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
        "            \n",
        "        \n",
        "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "    \n",
        "    cv2.imshow(\"Video\", frame)\n",
        "    \n",
        "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
        "        break\n",
        "            \n",
        "        \n",
        "cap.release() #Release the resources after recording\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2ECdWBY3lBd"
      },
      "source": [
        "### Face Detection in Real-Time\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t13GBden3lBe"
      },
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(0) #If you want to display the Video File, just give the name of it inplace of 0\n",
        "\n",
        "#Videos are just a sequence of Images\n",
        "#So, we will add a while loop to capture the frame continuously\n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "\n",
        "while True:\n",
        "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
        "            \n",
        "        \n",
        "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),3)\n",
        "    \n",
        "    cv2.imshow(\"Video\", frame)\n",
        "    \n",
        "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
        "        break\n",
        "            \n",
        "        \n",
        "cap.release() #Release the resources after recording\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofF8Wxs43lBe"
      },
      "source": [
        "### Face & Eyes Detection in Real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln3hrRUz3lBe"
      },
      "source": [
        "#Face and Eyes Detection in Real-Time\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "#Videos are just a sequence of Images\n",
        "#So, we will add a while loop to capture the frame continuously\n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
        "faceCascade1 = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "\n",
        "while True:\n",
        "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
        "            \n",
        "        \n",
        "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    eyes = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
        "    faces = faceCascade1.detectMultiScale(imgGray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
        "    \n",
        "    for (x, y, w, h) in eyes:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
        "    \n",
        "    cv2.imshow(\"Video\", frame)\n",
        "    \n",
        "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
        "        break\n",
        "            \n",
        "        \n",
        "cap.release() #Release the resources after recording\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vgTJFKI3lBf"
      },
      "source": [
        "### Pedestrians Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbYZz7pl3lBf"
      },
      "source": [
        "cap = cv2.VideoCapture('vtest.avi') #note - insert a video link here\n",
        "\n",
        "#Videos are just a sequence of Images\n",
        "#So, we will add a while loop to capture the frame continuously\n",
        "\n",
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
        "\n",
        "\n",
        "while True:\n",
        "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
        "            \n",
        "        \n",
        "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
        "    \n",
        "    cv2.imshow(\"Video\", frame)\n",
        "    \n",
        "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
        "        break\n",
        "            \n",
        "        \n",
        "cap.release() #Release the resources after recording\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_twVz6AX3lBi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}